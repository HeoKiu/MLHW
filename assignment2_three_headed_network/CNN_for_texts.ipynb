{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13pL--6rycN3"
      },
      "source": [
        "## Homework02: Three headed network in PyTorch\n",
        "\n",
        "This notebook accompanies the [week02](https://github.com/girafe-ai/natural-language-processing/tree/master/week02_cnn_for_texts) practice session. Refer to that notebook for more comments.\n",
        "\n",
        "All the preprocessing is the same as in the classwork. *Including the data leakage in the train test split (it's still for bonus points).*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "P8zS7m-gycN5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import nltk\n",
        "import tqdm\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjPBL85dpfpP"
      },
      "source": [
        "If you have already downloaded the data on the Seminar, simply run through the next cells. Otherwise uncomment the next cell (and comment the another one ;)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfzczckupfpP",
        "outputId": "0ba9902b-2b0a-4aea-b21b-2e1a62ba0bdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100    17    0    17    0     0     25      0 --:--:-- --:--:-- --:--:--    25\n",
            "100   342  100   342    0     0    291      0  0:00:01  0:00:01 --:--:--     0\n",
            "100  119M  100  119M    0     0  18.4M      0  0:00:06  0:00:06 --:--:-- 26.9M\n",
            "Train_rev1.csv\n",
            "--2023-05-30 01:33:31--  https://raw.githubusercontent.com/girafe-ai/natural-language-processing/22f_msai/homeworks/assignment02_three_headed_network/network.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1469 (1.4K) [text/plain]\n",
            "Saving to: ‘network.py.1’\n",
            "\n",
            "network.py.1        100%[===================>]   1.43K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-05-30 01:33:31 (22.2 MB/s) - ‘network.py.1’ saved [1469/1469]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!curl -L \"https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=1\" -o Train_rev1.csv.tar.gz\n",
        "!tar -xvzf ./Train_rev1.csv.tar.gz\n",
        "\n",
        "data = pd.read_csv(\"./Train_rev1.csv\", index_col=None)\n",
        "\n",
        "!wget https://raw.githubusercontent.com/girafe-ai/natural-language-processing/22f_msai/homeworks/assignment02_three_headed_network/network.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "UuuKIKfrycOH"
      },
      "outputs": [],
      "source": [
        "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
        "text_columns = [\"Title\", \"FullDescription\"]\n",
        "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
        "target_column = \"Log1pSalary\"\n",
        "\n",
        "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
        "\n",
        "data.sample(3)\n",
        "\n",
        "\n",
        "data_for_autotest = data[-5000:]\n",
        "data = data[:-5000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUWkpd7PycOQ",
        "outputId": "1d27759c-ce94-4853-97a4-4e1c43b7a297"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized:\n",
            "2         mathematical modeller / simulation analyst / o...\n",
            "100002    a successful and high achieving specialist sch...\n",
            "200002    web designer html , css , javascript , photosh...\n",
            "Name: FullDescription, dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "239768it [00:25, 9308.54it/s] \n"
          ]
        }
      ],
      "source": [
        "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
        "# see task above\n",
        "def normalize(text):\n",
        "    text = str(text).lower()\n",
        "    return ' '.join(tokenizer.tokenize(text))\n",
        "    \n",
        "data[text_columns] = data[text_columns].applymap(normalize)\n",
        "\n",
        "print(\"Tokenized:\")\n",
        "print(data[\"FullDescription\"][2::100000])\n",
        "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
        "assert data[\"Title\"][54321] == 'international digital account manager ( german )'\n",
        "\n",
        "# Count how many times does each token occur in both \"Title\" and \"FullDescription\" in total\n",
        "# build a dictionary { token -> it's count }\n",
        "from collections import Counter\n",
        "from tqdm import tqdm as tqdm\n",
        "\n",
        "token_counts = Counter()# <YOUR CODE HERE>\n",
        "for _, row in tqdm(data[text_columns].iterrows()):\n",
        "    for string in row:\n",
        "        token_counts.update(string.split())\n",
        "\n",
        "# hint: you may or may not want to use collections.Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOwtyw_cpfpT",
        "outputId": "ab99c98c-1fab-4dc3-bddf-f442799ffa6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2598827"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ],
      "source": [
        "token_counts.most_common(1)[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiOWbc15ycOb",
        "outputId": "ce248128-81f1-4e3e-ccf2-fff0a96b7541"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique tokens : 201127\n",
            "('and', 2598827)\n",
            "('.', 2471477)\n",
            "(',', 2266256)\n",
            "('the', 2036428)\n",
            "('to', 1977039)\n",
            "...\n",
            "('dbms_stats', 1)\n",
            "('dbms_output', 1)\n",
            "('dbms_job', 1)\n",
            "Correct!\n",
            "Vocabulary size: 33795\n",
            "Correct!\n",
            "Correct!\n"
          ]
        }
      ],
      "source": [
        "print(\"Total unique tokens :\", len(token_counts))\n",
        "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
        "print('...')\n",
        "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
        "\n",
        "assert token_counts.most_common(1)[0][1] in  range(2500000, 2700000)\n",
        "assert len(token_counts) in range(200000, 210000)\n",
        "print('Correct!')\n",
        "\n",
        "min_count = 10\n",
        "\n",
        "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
        "tokens = [token for token, count in token_counts.items() if count >= min_count]# <YOUR CODE HERE>\n",
        "# Add a special tokens for unknown and empty words\n",
        "UNK, PAD = \"UNK\", \"PAD\"\n",
        "tokens = [UNK, PAD] + sorted(tokens)\n",
        "print(\"Vocabulary size:\", len(tokens))\n",
        "\n",
        "assert type(tokens) == list\n",
        "assert len(tokens) in range(32000, 35000)\n",
        "assert 'me' in tokens\n",
        "assert UNK in tokens\n",
        "print(\"Correct!\")\n",
        "\n",
        "token_to_id = {token: idx for idx, token in enumerate(tokens)}\n",
        "assert isinstance(token_to_id, dict)\n",
        "assert len(token_to_id) == len(tokens)\n",
        "for tok in tokens:\n",
        "    assert tokens[token_to_id[tok]] == tok\n",
        "\n",
        "print(\"Correct!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "JEsLeBjVycOw"
      },
      "outputs": [],
      "source": [
        "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
        "\n",
        "def as_matrix(sequences, max_len=None):\n",
        "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
        "    if isinstance(sequences[0], str):\n",
        "        sequences = list(map(str.split, sequences))\n",
        "        \n",
        "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
        "    \n",
        "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
        "    for i,seq in enumerate(sequences):\n",
        "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
        "        matrix[i, :len(row_ix)] = row_ix\n",
        "    \n",
        "    return matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiBlPkdKycOy",
        "outputId": "3c6eadfd-2ea6-4175-de91-3ea1aefa1e0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lines:\n",
            "engineering systems analyst\n",
            "hr assistant\n",
            "senior ec & i engineer\n",
            "\n",
            "Matrix:\n",
            "[[10705 29830  2143     1     1]\n",
            " [14875  2817     1     1     1]\n",
            " [27345 10107    15 15069 10702]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Lines:\")\n",
        "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
        "print(\"Matrix:\")\n",
        "print(as_matrix(data[\"Title\"][::100000]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "DpOlBp7ZycO6",
        "outputId": "04c34ae6-a680-4b65-ae37-3f714d49a2fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DictVectorizer(dtype=<class 'numpy.float32'>, sparse=False)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DictVectorizer</label><div class=\"sk-toggleable__content\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ],
      "source": [
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "# we only consider top-1k most frequent companies to minimize memory usage\n",
        "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
        "recognized_companies = set(top_companies)\n",
        "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
        "\n",
        "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
        "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk4jmtAYycO8"
      },
      "source": [
        "### The deep learning part\n",
        "\n",
        "Once we've learned to tokenize the data, let's design a machine learning experiment.\n",
        "\n",
        "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
        "\n",
        "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes.\n",
        "\n",
        "\n",
        "#### Here comes the simple one-headed network from the seminar. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TngLcWA0ycO_",
        "outputId": "d7656181-a288-4720-f981-9bfaf1298a8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size =  191814\n",
            "Validation size =  47954\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
        "data_train.index = range(len(data_train))\n",
        "data_val.index = range(len(data_val))\n",
        "\n",
        "print(\"Train size = \", len(data_train))\n",
        "print(\"Validation size = \", len(data_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "2PXuKgOSycPB"
      },
      "outputs": [],
      "source": [
        "def make_batch(data, max_len=None, word_dropout=0):\n",
        "    \"\"\"\n",
        "    Creates a keras-friendly dict from the batch data.\n",
        "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
        "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
        "    \"\"\"\n",
        "    batch = {}\n",
        "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
        "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
        "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
        "    \n",
        "    if word_dropout != 0:\n",
        "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
        "    \n",
        "    if target_column in data.columns:\n",
        "        batch[target_column] = data[target_column].values\n",
        "    \n",
        "    return batch\n",
        "\n",
        "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
        "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
        "    dropout_mask &= matrix != pad_ix\n",
        "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "I6LpEQf0ycPD"
      },
      "outputs": [],
      "source": [
        "a = make_batch(data_train[:3], max_len=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em39YVkkpfpW"
      },
      "source": [
        "But to start with let's build the simple model using only the part of the data. Let's create the baseline solution using only the description part (so it should definetely fit into the Sequential model)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "ckgBNTW_pfpW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "_W_f9aJspfpW"
      },
      "outputs": [],
      "source": [
        "# You will need these to make it simple\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "class Reorder(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.permute((0, 2, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWQfK1QIpfpX"
      },
      "source": [
        "To generate minibatches we will use simple pyton generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "T1NjqbPtpfpX"
      },
      "outputs": [],
      "source": [
        "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, **kwargs):\n",
        "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
        "    while True:\n",
        "        indices = np.arange(len(data))\n",
        "        if shuffle:\n",
        "            indices = np.random.permutation(indices)\n",
        "\n",
        "        for start in range(0, len(indices), batch_size):\n",
        "            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n",
        "            target = batch.pop(target_column)\n",
        "            yield batch, target\n",
        "        \n",
        "        if not cycle: break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "hvjK1oD7pfpX"
      },
      "outputs": [],
      "source": [
        "iterator = iterate_minibatches(data_train, 3)\n",
        "batch, target = next(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "5jq32ZZGpfpX"
      },
      "outputs": [],
      "source": [
        "# Here is some startup code:\n",
        "n_tokens=len(tokens)\n",
        "n_cat_features=len(categorical_vectorizer.vocabulary_)\n",
        "hid_size=64\n",
        "simple_model = nn.Sequential()\n",
        "\n",
        "simple_model.add_module('emb', nn.Embedding(num_embeddings=n_tokens, embedding_dim=hid_size))\n",
        "simple_model.add_module('reorder', Reorder())\n",
        "simple_model.add_module('conv1', nn.Conv1d(\n",
        "    in_channels=hid_size,\n",
        "    out_channels=hid_size,\n",
        "    kernel_size=2)\n",
        "                       )\n",
        "simple_model.add_module('relu1', nn.ReLU())\n",
        "simple_model.add_module('adapt_avg_pool', nn.AdaptiveAvgPool1d(output_size=1))\n",
        "simple_model.add_module('flatten1', Flatten())\n",
        "simple_model.add_module('linear1', nn.Linear(in_features=hid_size, out_features=1))\n",
        "# <YOUR CODE HERE>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ripT9yWDpfpY",
        "outputId": "256acf11-7e39-4015-a224-708c3fee342f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Title': array([[10572,  7252,   195,  1175, 18670, 32827, 30762, 33306],\n",
              "        [17890,  6739, 32128, 30145,  2436,     1,     1,     1],\n",
              "        [20640,  8992,  5030,   156,    80,     1,     1,     1]],\n",
              "       dtype=int32),\n",
              " 'FullDescription': array([[ 2545, 33635, 33331, 33209, 32827, 30762, 33306,   927, 25112,\n",
              "           927,  9526, 33635, 14109, 11453, 33331, 33198,  5223, 33010,\n",
              "         20573, 10572,   927, 33403, 33635, 17898, 30762, 33306, 12466,\n",
              "           965,  6835, 33010,  3725, 15402, 16416, 22680,  2662, 20193,\n",
              "          2662, 16416, 25916,   927, 20386,  6347, 16289, 25045,  2662,\n",
              "           965, 17576, 23189, 33209, 16416, 12023, 15402, 32827, 30762,\n",
              "         33306,   167, 30898,  6782, 30762,  1243,     0,  4978,  1973,\n",
              "          8595, 30762, 30411, 32827, 21405, 30411, 30080,   167, 29570,\n",
              "          5016,  7332, 15389,   156, 31046,  2166,  9000,   156, 30512,\n",
              "         23115, 26324, 33079, 33306, 33198,   965,  5459, 21405, 20208,\n",
              "          9286,  5223,   156,  2832, 30426, 33198, 30422, 10561, 28011,\n",
              "           156,  8167,   156, 16059, 30149,   156,  7088,  4835,  2166,\n",
              "         29574, 30426,  3259, 30762, 33306,   167, 30279,   156,  8597,\n",
              "          2166, 10815, 16289, 11068, 30762, 30411, 29402, 21405, 30512,\n",
              "         26324,  2662, 16289,   965, 24240,  3268, 15402,  1243, 25916,\n",
              "         33209, 30411, 25112,   195, 32827, 30762, 33306, 15563,   167,\n",
              "         17041, 25861, 33079, 15444, 15155, 15538, 17610, 20581,   156,\n",
              "         23148, 31046,  2166,  9000,   156, 25083, 15652,   156, 10628,\n",
              "         27236, 11092,  2166,  4835, 31823,  7088,  2166, 11660, 13699,\n",
              "         17610, 30578, 20040,   156, 23778,  2166, 30080, 33306,   167,\n",
              "          2120, 11295, 25558, 22170, 16289, 21417, 30785, 33198,   965,\n",
              "          6777, 30762,  7332, 31046,  2166, 30411, 31952, 24204,  2840,\n",
              "         33198,   965, 12578, 30501,   156, 23936,  2166,  8595, 24249,\n",
              "           167, 12466, 12913, 15652,   156,  7280, 20809,  2892, 33642,\n",
              "         10031,  7381,   167, 30512, 16658, 32637, 21870, 23459,  2662,\n",
              "         33468,   167, 30895,   167,  6681,   195, 16679,   195,     0,\n",
              "            80],\n",
              "        [30512, 16289, 30411, 16658, 30407, 16289, 21464, 29025, 17211,\n",
              "          2662, 30411,  5303, 19195,  1993, 33209, 30411, 15563, 30411,\n",
              "         30311, 27445, 30145, 14083,  3682, 33045, 31923, 12466, 18781,\n",
              "         33591,   167,  2662,   965, 27445, 30145, 33635, 33742, 18065,\n",
              "          3607, 33331, 21556,  8090, 32130,  2166, 13252, 30762, 13664,\n",
              "         33198,  1894, 30411, 17465,  9080, 10944,  2166, 30160,   167,\n",
              "          2662, 32828,  2662,  5426, 21977, 27468,  2166, 25618,   156,\n",
              "         33635, 33742, 18065, 17605, 14850, 30762, 25642,  6948, 31946,\n",
              "         28537, 10944,   167,  8998,  4353, 33642, 30442,  2166, 23574,\n",
              "         28011,   156, 33635, 33742, 18065, 17605, 14850, 30762,  9075,\n",
              "          2166, 25618, 11844,   156,  2166, 22719, 26451, 18594, 10781,\n",
              "          8130,  5428, 26558,  2892, 30422, 32205,  3837,   167, 30411,\n",
              "         27445, 30145,  2439, 21050, 29905,   555, 33591, 30762,  6911,\n",
              "         30762, 17758,   555,   167, 33635, 33079,  2964,   965,  6649,\n",
              "         21405, 12913, 10230, 12466, 10327,  8422, 25467, 21784,  4112,\n",
              "         25467,   167, 15187, 33635, 33403, 17898, 30762,  2395, 12466,\n",
              "         30512,  2439,   156, 23212, 27339, 33642,  8167, 30762, 30411,\n",
              "         10471,  1400,  3742,   167,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1],\n",
              "        [  167, 20640,  8992, 21972,  6347, 16289,   965, 17576, 24249,\n",
              "         21405, 21593, 14789,  7865,  2166, 30232, 29830,   167, 30487,\n",
              "          8894,   156,  8988,  2166,  8816, 14491,   156, 18310, 18594,\n",
              "         21296,  6539, 31946,  8164, 10191, 30157,   167, 32718, 14109,\n",
              "           965, 32205, 11320, 21721, 12466,   965,   167, 20640, 27345,\n",
              "          8992, 30762, 16729,  2120, 11320,   156, 11404,  9000, 30080,\n",
              "           167, 33635, 33079, 33306, 21556,   965, 33043, 32075, 21405,\n",
              "          8114, 11669, 24114,   156, 31946,   965,     0, 21405, 30157,\n",
              "         15447,  5030,   156, 17973,   156, 24899, 12661,   156, 33416,\n",
              "           156, 32709,   156,  2103,   156,  5030,   156, 26543,   156,\n",
              "         16528,   156, 31326,  2166, 19981, 15402,   965, 11804, 20103,\n",
              "           156,  7792,  9000, 10866,   167, 30512, 16289,   965, 13597,\n",
              "         21721, 30762, 33306, 33198, 30411, 17465, 30157,  2166, 18606,\n",
              "           965, 24922,  9142, 33209,   965, 28133,   156, 10817,   156,\n",
              "         14477, 12397,   156, 29915,  2166, 12578, 30501, 30080,   167,\n",
              "         11068, 28011,   891, 19527,   167, 20640,    80, 33198,  2892,\n",
              "         17622,   555, 33591, 24002, 11453, 19527, 28709, 27438,    41,\n",
              "         10815,  2166,   965,  8913, 30762, 17605,  1390, 28011,   891,\n",
              "         11453, 33198, 21950, 17422, 15402,  1389, 30762,  5030,   891,\n",
              "         26543,   156,  5030,   156, 16528, 17979, 24678, 20128, 11453,\n",
              "         15402, 30232, 23177, 33403,  3607,  1533,  4978, 21084, 11068,\n",
              "           167, 15402, 25977, 21972,  6347, 16289, 21419, 31823, 30762,\n",
              "            80, 16873,   156,  4266,  2166,  3771,   167,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1]], dtype=int32),\n",
              " 'Categorical': array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)}"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ],
      "source": [
        "batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABpk3zLWpfpY"
      },
      "source": [
        "__Remember!__ We are working with regression problem and predicting only one number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmN0rBGjpfpY",
        "outputId": "41ae7579-af3f-40eb-a098-206e6962ee0e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0828],\n",
              "        [0.0060],\n",
              "        [0.0523]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ],
      "source": [
        "# Try this to check your model. `torch.long` tensors are required for nn.Embedding layers.\n",
        "simple_model(torch.tensor(batch['FullDescription'], dtype=torch.long))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouLf5g7bpfpY",
        "outputId": "2dd2eff9-a99e-4d3d-e85e-86c3cef38061"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 235)"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ],
      "source": [
        "batch['FullDescription'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6Dszj8HpfpZ"
      },
      "source": [
        "And now simple training pipeline (it's commented because we've already done that in class. No need to do it again)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "Um6Wmv5XpfpZ"
      },
      "outputs": [],
      "source": [
        "# from IPython.display import clear_output\n",
        "# from random import sample\n",
        "\n",
        "# epochs = 1\n",
        "\n",
        "# model = simple_model\n",
        "# opt = torch.optim.Adam(model.parameters())\n",
        "# loss_func = nn.MSELoss()\n",
        "\n",
        "# history = []\n",
        "# for epoch_num in range(epochs):\n",
        "#     for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n",
        "#         # Preprocessing the batch data and target\n",
        "#         batch = torch.tensor(batch['FullDescription'], dtype=torch.long)\n",
        "\n",
        "#         target = torch.tensor(target)\n",
        "\n",
        "\n",
        "#         predictions = model(batch)\n",
        "#         predictions = predictions.view(predictions.size(0))\n",
        "\n",
        "#         loss = loss_func(predictions, target)# <YOUR CODE HERE>\n",
        "\n",
        "#         # train with backprop\n",
        "#         loss.backward()\n",
        "#         opt.step()\n",
        "#         opt.zero_grad()\n",
        "#         # <YOUR CODE HERE>\n",
        "\n",
        "#         history.append(loss.data.numpy())\n",
        "#         if (idx+1)%10==0:\n",
        "#             clear_output(True)\n",
        "#             plt.plot(history,label='loss')\n",
        "#             plt.legend()\n",
        "#             plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Af2iZI-EpfpZ"
      },
      "source": [
        "### Actual homework starts here\n",
        "__Your ultimate task is to code the three headed network described on the picture below.__ \n",
        "To make it closer to the real world, please store the network code in file `network.py` in this directory. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eI5h9UMycPF"
      },
      "source": [
        "#### Architecture\n",
        "\n",
        "Our main model consists of three branches:\n",
        "* Title encoder\n",
        "* Description encoder\n",
        "* Categorical features encoder\n",
        "\n",
        "We will then feed all 3 branches into one common network that predicts salary.\n",
        "\n",
        "<img src=\"https://github.com/yandexdataschool/nlp_course/raw/master/resources/w2_conv_arch.png\" width=600px>\n",
        "\n",
        "This clearly doesn't fit into PyTorch __Sequential__ interface. To build such a network, one will have to use [__PyTorch nn.Module API__](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "id": "8TeoJXwIpfpa"
      },
      "outputs": [],
      "source": [
        "import network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OMu_Wpzpfpa",
        "outputId": "14f55b5b-4a88-4b58-c3a7-5f1c84540fd9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'network' from '/content/network.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ],
      "source": [
        "# Re-run this cell if you updated the file with network source code\n",
        "import imp\n",
        "imp.reload(network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "id": "cRie0_VVpfpa"
      },
      "outputs": [],
      "source": [
        "model = network.ThreeInputsNet(\n",
        "    n_tokens=len(tokens),\n",
        "    n_cat_features=len(categorical_vectorizer.vocabulary_),\n",
        "\n",
        "    # this parameter defines the number of the inputs in the layer,\n",
        "    # which stands after the concatenation. In should be found out by you.\n",
        "    concat_number_of_features=100\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "id": "jhv14SLjpfpa"
      },
      "outputs": [],
      "source": [
        "testing_batch, _ = next(iterate_minibatches(data_train, 3))\n",
        "testing_batch = [\n",
        "    torch.tensor(testing_batch['Title'], dtype=torch.long),\n",
        "    torch.tensor(testing_batch['FullDescription'], dtype=torch.long),\n",
        "    torch.tensor(testing_batch['Categorical'])\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZBzBMkhpfpb",
        "outputId": "04189960-2048-46fd-ccc7-2be0942c682c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seems fine!\n"
          ]
        }
      ],
      "source": [
        "assert model(testing_batch).shape == torch.Size([3, 1])\n",
        "assert model(testing_batch).dtype == torch.float32\n",
        "print('Seems fine!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O64sbfShpfpb"
      },
      "source": [
        "Now train the network for a while (100 batches would be fine)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')\n"
      ],
      "metadata": {
        "id": "O-RecWcHJ1MP"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training pipeline comes here (almost the same as for the simple_model)\n",
        "\n",
        "epochs = 1\n",
        "\n",
        "model = model.to(device)\n",
        "opt = torch.optim.Adam(model.parameters())\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "history = []\n",
        "for epoch_num in range(epochs):\n",
        "    for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n",
        "        # Preprocessing the batch data and target\n",
        "        batch_title = torch.tensor(batch['Title'], dtype=torch.long).to(device)\n",
        "        batch_full = torch.tensor(batch['FullDescription'], dtype=torch.long).to(device)\n",
        "        batch_category = torch.tensor(batch['Categorical']).to(device)\n",
        "        \n",
        "        target = torch.tensor(target).to(device)\n",
        "        \n",
        "        whole_input = [batch_title, batch_full, batch_category]\n",
        "\n",
        "\n",
        "        predictions = model(whole_input)\n",
        "        predictions = predictions.view(predictions.size(0))\n",
        "\n",
        "        loss = loss_func(predictions, target)# <YOUR CODE HERE>\n",
        "\n",
        "        # train with backprop\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "        history.append(loss.item())\n",
        "        if (idx+1)%10==0:\n",
        "            clear_output(True)\n",
        "            plt.plot(history,label='loss')\n",
        "            plt.legend()\n",
        "            plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "RVAwp69sOfRv",
        "outputId": "7d483fd8-2373-4592-9a4c-34de47f16cc7"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "melECI5gpfpb"
      },
      "source": [
        "Now, to evaluate the model it can be switched to `eval` state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hb40tQXhpfpt",
        "outputId": "12d8a7db-920b-41b6-dbde-5921a52f9500"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ThreeInputsNet(\n",
              "  (title_emb): Embedding(33795, 64)\n",
              "  (title_proc): Sequential(\n",
              "    (0): Conv1d(64, 64, kernel_size=(2,), stride=(1,))\n",
              "    (1): AdaptiveAvgPool1d(output_size=1)\n",
              "  )\n",
              "  (full_emb): Embedding(33795, 64)\n",
              "  (full_proc): Sequential(\n",
              "    (0): Conv1d(64, 128, kernel_size=(2,), stride=(1,))\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Conv1d(128, 128, kernel_size=(2,), stride=(1,))\n",
              "    (4): ReLU()\n",
              "    (5): AdaptiveAvgPool1d(output_size=1)\n",
              "  )\n",
              "  (category_out): Identity()\n",
              "  (relu): ReLU()\n",
              "  (post_concat): Linear(in_features=3938, out_features=100, bias=True)\n",
              "  (inter_dense): Linear(in_features=100, out_features=128, bias=True)\n",
              "  (final_dense): Linear(in_features=128, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "id": "_-5f7rB_pfpt"
      },
      "outputs": [],
      "source": [
        "def generate_submission(model, data, batch_size=256, name=\"\", three_inputs_mode=True, **kw):\n",
        "    squared_error = abs_error = num_samples = 0.0\n",
        "    output_list = []\n",
        "    for batch_x, batch_y in tqdm(iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw)):\n",
        "        if three_inputs_mode:\n",
        "            batch = [\n",
        "                torch.tensor(batch_x['Title'], dtype=torch.long),\n",
        "                torch.tensor(batch_x['FullDescription'], dtype=torch.long),\n",
        "                torch.tensor(batch_x['Categorical'])\n",
        "            ]\n",
        "        else:\n",
        "            batch = torch.tensor(batch_x['FullDescription'], dtype=torch.long)\n",
        "\n",
        "        batch_pred = model(batch)[:, 0].detach().numpy()\n",
        "        \n",
        "        output_list.append((list(batch_pred), list(batch_y)))\n",
        "        \n",
        "        squared_error += np.sum(np.square(batch_pred - batch_y))\n",
        "        abs_error += np.sum(np.abs(batch_pred - batch_y))\n",
        "        num_samples += len(batch_y)\n",
        "    print(\"%s results:\" % (name or \"\"))\n",
        "    print(\"Mean square error: %.5f\" % (squared_error / num_samples))\n",
        "    print(\"Mean absolute error: %.5f\" % (abs_error / num_samples))\n",
        "    \n",
        "\n",
        "    batch_pred = [c for x in output_list for c in x[0]]\n",
        "    batch_y = [c for x in output_list for c in x[1]]\n",
        "    output_df = pd.DataFrame(list(zip(batch_pred, batch_y)), columns=['batch_pred', 'batch_y'])\n",
        "    output_df.to_csv('submission.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_ateWZgpfpt",
        "outputId": "70b3a73a-ef59-47e9-8196-4c62f4aa0f9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20it [00:16,  1.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission results:\n",
            "Mean square error: 0.46869\n",
            "Mean absolute error: 0.59332\n",
            "Submission file generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cpu\")\n",
        "model.cpu()\n",
        "generate_submission(model, data_for_autotest, name='Submission')\n",
        "print('Submission file generated')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAeuqL5-pfpu"
      },
      "source": [
        "__Both the notebook and the `.py` file are required to submit this homework.__"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CNN_for_texts.ipynb",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
